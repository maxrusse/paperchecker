{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PaperChecker - Medical Research Paper Extraction\n",
    "\n",
    "Automated pipeline for extracting structured data from medical research PDFs.\n",
    "\n",
    "**Quick Start:**\n",
    "1. Run **Cell 1** (Setup) - once per session\n",
    "2. Run **Cell 2** (Load ZIP) - upload your code ZIP\n",
    "3. Run **Cell 3** (Run) - set PDF folder and extract!\n",
    "4. Run **Cell 4** (Download) - get your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **1. SETUP** (run once per session)\n",
    "#@markdown Installs dependencies, mounts Google Drive, loads API keys.\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -U openai google-genai pymupdf python-docx openpyxl jsonschema -q\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Load API keys from Colab Secrets\n",
    "from google.colab import userdata\n",
    "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "\n",
    "if OPENAI_API_KEY and GOOGLE_API_KEY:\n",
    "    print(\"[OK] Setup complete! API keys loaded.\")\n",
    "else:\n",
    "    print(\"[!] WARNING: Add OPENAI_API_KEY and GOOGLE_API_KEY to Colab Secrets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **2. LOAD ZIP** (run when code changes)\n",
    "#@markdown Upload and extract the PaperChecker ZIP file.\n",
    "\n",
    "from google.colab import files\n",
    "import os, shutil, zipfile\n",
    "\n",
    "project_dir = \"/content/paperchecker\"\n",
    "\n",
    "# Clean previous install\n",
    "if os.path.exists(project_dir):\n",
    "    shutil.rmtree(project_dir)\n",
    "\n",
    "print(\"Upload the PaperChecker ZIP file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if not uploaded:\n",
    "    raise RuntimeError(\"No file uploaded!\")\n",
    "\n",
    "zip_path = next(iter(uploaded.keys()))\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "    zf.extractall(\"/content\")\n",
    "    top_levels = {n.split(\"/\")[0] for n in zf.namelist() if n.strip()}\n",
    "\n",
    "# Handle nested folder from GitHub ZIP\n",
    "if len(top_levels) == 1:\n",
    "    extracted = os.path.join(\"/content\", next(iter(top_levels)))\n",
    "    if os.path.isdir(extracted) and extracted != project_dir:\n",
    "        os.rename(extracted, project_dir)\n",
    "\n",
    "%cd /content/paperchecker\n",
    "print(\"[OK] Code loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **3. RUN** (main cell - re-run for new PDFs)\n",
    "#@markdown Set your PDF folder path and run extraction.\n",
    "\n",
    "PDF_FOLDER = \"/content/drive/MyDrive/paperchecker/pdf\"  #@param {type:\"string\"}\n",
    "\n",
    "import os, glob\n",
    "from datetime import datetime, UTC\n",
    "\n",
    "# Reload script module (picks up any code changes)\n",
    "import importlib\n",
    "import script\n",
    "importlib.reload(script)\n",
    "\n",
    "# Find PDFs\n",
    "pdf_paths = sorted(glob.glob(os.path.join(PDF_FOLDER, \"*.pdf\")))\n",
    "print(f\"Found {len(pdf_paths)} PDF(s) in {PDF_FOLDER}\")\n",
    "for i, p in enumerate(pdf_paths, 1):\n",
    "    print(f\"  {i}. {os.path.basename(p)}\")\n",
    "\n",
    "if not pdf_paths:\n",
    "    raise RuntimeError(\"No PDFs found! Check PDF_FOLDER path.\")\n",
    "\n",
    "# Setup output paths\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "timestamp = datetime.now(UTC).strftime('%Y%m%d_%H%M%S')\n",
    "OUTPUT_XLSX = f\"output/mronj_extraction_{timestamp}.xlsx\"\n",
    "OUTPUT_DOCX = f\"output/mronj_review_log_{timestamp}.docx\"\n",
    "\n",
    "print(f\"\\nOutput: {OUTPUT_XLSX}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Run pipeline (template auto-generated from EXCEL_MAP)\n",
    "results = script.run_pipeline(\n",
    "    pdf_paths=pdf_paths,\n",
    "    out_xlsx=OUTPUT_XLSX,\n",
    "    out_docx=OUTPUT_DOCX,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    google_api_key=GOOGLE_API_KEY,\n",
    "    progress_fn=print,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"DONE! Processed {len(results)} paper(s)\")\n",
    "for i, r in enumerate(results, 1):\n",
    "    pid = r.get('paper_id', {})\n",
    "    print(f\"  {i}. PMID={pid.get('pmid')} | {r.get('study_type')} | review={r.get('validation',{}).get('needs_human_review')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **4. DOWNLOAD** (get results)\n",
    "#@markdown Download Excel, Word, and audit files.\n",
    "\n",
    "from google.colab import files\n",
    "import glob\n",
    "\n",
    "print(\"Downloading results...\\n\")\n",
    "\n",
    "for f in [OUTPUT_XLSX, OUTPUT_DOCX] + glob.glob(\"output/*.audit_*.json\"):\n",
    "    if os.path.exists(f):\n",
    "        print(f\"  {f}\")\n",
    "        files.download(f)\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Troubleshooting\n",
    "\n",
    "**API Keys:** Add `OPENAI_API_KEY` and `GOOGLE_API_KEY` in Colab sidebar > Secrets\n",
    "\n",
    "**No PDFs:** Check `PDF_FOLDER` path (e.g., `/content/drive/MyDrive/your_folder`)\n",
    "\n",
    "**Model errors:** Edit `script.py` lines 58-59 to change models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
