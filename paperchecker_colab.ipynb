{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PaperChecker - Medical Research Paper Extraction\n",
        "\n",
        "This notebook runs **PaperChecker v2** - an automated pipeline for extracting structured data from medical research PDFs (focused on MRONJ prevention studies).\n",
        "\n",
        "## What it does:\n",
        "- Extracts metadata, population data, drug information, interventions, and outcomes from PDFs\n",
        "- Fills an Excel template with standardized data\n",
        "- Verifies extracted information using a second LLM pass\n",
        "- Generates a Word review log documenting all decisions\n",
        "\n",
        "## Requirements:\n",
        "- OpenAI API key\n",
        "- Google AI (Gemini) API key\n",
        "- PDF files to process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 1: Clone Repository & Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the PaperChecker repository\n",
        "!git clone https://github.com/maxrusse/paperchecker.git\n",
        "%cd paperchecker\n",
        "\n",
        "# Install required dependencies\n",
        "!pip install -U openai google-genai pymupdf python-docx openpyxl jsonschema -q\n",
        "\n",
        "print(\"\\n Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 2: Enter Your API Keys\n",
        "\n",
        "Enter your API keys below. They will be stored securely in this session only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "# Securely input API keys (won't be displayed)\n",
        "OPENAI_API_KEY = getpass(\"Enter your OpenAI API Key: \")\n",
        "GOOGLE_API_KEY = getpass(\"Enter your Google AI (Gemini) API Key: \")\n",
        "\n",
        "if OPENAI_API_KEY and GOOGLE_API_KEY:\n",
        "    print(\" API keys saved for this session!\")\n",
        "else:\n",
        "    print(\" Warning: One or both API keys are missing!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 3: Upload Your PDF Files\n",
        "\n",
        "Upload the medical research papers you want to process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Create uploads directory\n",
        "os.makedirs(\"uploads\", exist_ok=True)\n",
        "\n",
        "print(\"Select PDF files to upload...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Save uploaded files and collect paths\n",
        "pdf_paths = []\n",
        "for filename, content in uploaded.items():\n",
        "    if filename.lower().endswith('.pdf'):\n",
        "        filepath = os.path.join(\"uploads\", filename)\n",
        "        with open(filepath, 'wb') as f:\n",
        "            f.write(content)\n",
        "        pdf_paths.append(os.path.abspath(filepath))\n",
        "        print(f\"  Saved: {filename}\")\n",
        "    else:\n",
        "        print(f\"  Skipped (not PDF): {filename}\")\n",
        "\n",
        "print(f\"\\n Total PDFs ready: {len(pdf_paths)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 4: Configure & Run PaperChecker\n",
        "\n",
        "Run the extraction pipeline on your uploaded PDFs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime, UTC\n",
        "\n",
        "# Import the PaperChecker script\n",
        "import script\n",
        "\n",
        "# Configuration\n",
        "TEMPLATE_XLSX = \"Prevention of MRONJ_Extraction Sheet (Oli).xlsx\"\n",
        "timestamp = datetime.now(UTC).strftime('%Y%m%d_%H%M%S')\n",
        "OUTPUT_XLSX = f\"output/mronj_extraction_{timestamp}.xlsx\"\n",
        "OUTPUT_DOCX = f\"output/mronj_review_log_{timestamp}.docx\"\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PaperChecker v2 - Starting Pipeline\")\n",
        "print(\"=\"*60)\n",
        "print(f\"PDFs to process: {len(pdf_paths)}\")\n",
        "print(f\"Template: {TEMPLATE_XLSX}\")\n",
        "print(f\"Output Excel: {OUTPUT_XLSX}\")\n",
        "print(f\"Output Word: {OUTPUT_DOCX}\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Run the pipeline\n",
        "try:\n",
        "    results = script.run_pipeline(\n",
        "        pdf_paths=pdf_paths,\n",
        "        template_xlsx=TEMPLATE_XLSX,\n",
        "        out_xlsx=OUTPUT_XLSX,\n",
        "        out_docx=OUTPUT_DOCX,\n",
        "        openai_api_key=OPENAI_API_KEY,\n",
        "        google_api_key=GOOGLE_API_KEY,\n",
        "        progress_fn=print,\n",
        "        use_gemini_driver=False,    # Use OpenAI for extraction\n",
        "        use_openai_verifier=False,  # Use Gemini for verification\n",
        "    )\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\" Pipeline completed successfully!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nProcessed {len(results)} paper(s)\")\n",
        "    \n",
        "    # Summary\n",
        "    for i, r in enumerate(results):\n",
        "        pid = r.get('paper_id', {})\n",
        "        val = r.get('validation', {})\n",
        "        print(f\"\\n  Paper {i+1}:\")\n",
        "        print(f\"    PMID: {pid.get('pmid', 'N/A')}\")\n",
        "        print(f\"    Study Type: {r.get('study_type', 'N/A')}\")\n",
        "        print(f\"    Needs Human Review: {val.get('needs_human_review', 'N/A')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n Error: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 5: Download Results\n",
        "\n",
        "Download the generated Excel and Word files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import glob\n",
        "\n",
        "print(\"Downloading output files...\\n\")\n",
        "\n",
        "# Download Excel file\n",
        "if os.path.exists(OUTPUT_XLSX):\n",
        "    print(f\"  Downloading: {OUTPUT_XLSX}\")\n",
        "    files.download(OUTPUT_XLSX)\n",
        "\n",
        "# Download Word file\n",
        "if os.path.exists(OUTPUT_DOCX):\n",
        "    print(f\"  Downloading: {OUTPUT_DOCX}\")\n",
        "    files.download(OUTPUT_DOCX)\n",
        "\n",
        "# Download audit JSON files\n",
        "audit_files = glob.glob(\"output/*.audit_*.json\")\n",
        "for audit_file in audit_files:\n",
        "    print(f\"  Downloading: {audit_file}\")\n",
        "    files.download(audit_file)\n",
        "\n",
        "print(\"\\n Download complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Optional: View Output Files in Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all generated output files\n",
        "import os\n",
        "\n",
        "print(\"Generated files in output/ directory:\\n\")\n",
        "for f in os.listdir(\"output\"):\n",
        "    filepath = os.path.join(\"output\", f)\n",
        "    size_kb = os.path.getsize(filepath) / 1024\n",
        "    print(f\"  {f} ({size_kb:.1f} KB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Troubleshooting\n",
        "\n",
        "**API Key Errors:**\n",
        "- Make sure you have valid API keys for both OpenAI and Google AI\n",
        "- OpenAI: https://platform.openai.com/api-keys\n",
        "- Google AI: https://makersuite.google.com/app/apikey\n",
        "\n",
        "**Model Access:**\n",
        "- The default models are `gpt-5.2` and `gemini-3-pro-preview`\n",
        "- If you don't have access, edit `script.py` lines 47-48 to use models you have access to\n",
        "\n",
        "**File Upload Issues:**\n",
        "- Only PDF files are accepted\n",
        "- Large files may take longer to upload\n",
        "\n",
        "**Processing Errors:**\n",
        "- Check the error message for specific issues\n",
        "- Ensure PDFs are valid and contain readable text"
      ]
    }
  ]
}
