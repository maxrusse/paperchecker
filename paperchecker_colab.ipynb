{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PaperChecker (Colab)\n",
        "\n",
        "Run the end-to-end pipeline: **PDF \u2192 JSON (driver) \u2192 JSON (verifier) \u2192 validation \u2192 Excel + Word outputs**.\n",
        "\n",
        "Use the **Open in Colab** badge in the README to launch this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip -q install -U openai google-genai pymupdf python-docx openpyxl jsonschema\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## API keys\n",
        "\n",
        "Set your API keys via Colab secrets or environment variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Option 1: set env vars directly (not recommended for shared notebooks)\n",
        "# os.environ['OPENAI_API_KEY'] = '...'\n",
        "# os.environ['GOOGLE_API_KEY'] = '...'\n",
        "\n",
        "# Option 2: use Colab secrets (recommended)\n",
        "# from google.colab import userdata\n",
        "# os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "# os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload PDFs and template\n",
        "\n",
        "Upload PDFs and the Excel template into `/content`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# After upload, set paths like:\n",
        "# PDF_PATHS = ['/content/paper1.pdf']\n",
        "# TEMPLATE_XLSX = '/content/Prevention of MRONJ_Extraction Sheet (Oli).xlsx'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline code\n",
        "\n",
        "The full pipeline implementation is below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# End-to-end pipeline: PDF -> Driver(JSON) -> Verifier(JSON, all critical decisions) -> Validator -> Excel + Word (human review log)\n",
        "#\n",
        "# Dependencies (pip):\n",
        "#   pip install -U openai google-genai pymupdf python-docx openpyxl jsonschema\n",
        "#\n",
        "# Notes:\n",
        "# - All critical decisions are forced through a verifier review with evidence + explanation.\n",
        "# - Output always writes Excel + Word as long as at least one verifier pass exists.\n",
        "# - Any DISAGREE/UNSURE or missing review becomes a CRITICAL validation issue and is clearly logged in Word.\n",
        "\n",
        "import os, json, re, copy\n",
        "from datetime import datetime, UTC\n",
        "import fitz  # PyMuPDF\n",
        "import openpyxl\n",
        "from docx import Document\n",
        "\n",
        "from openai import OpenAI\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG\n",
        "# -------------------------\n",
        "PDF_PATHS = [\n",
        "    # Example:\n",
        "    # \"/mnt/data/paper1.pdf\",\n",
        "]\n",
        "\n",
        "TEMPLATE_XLSX = \"/mnt/data/Prevention of MRONJ_Extraction Sheet (Oli).xlsx\"\n",
        "OUT_XLSX = f\"/mnt/data/mronj_prevention_filled_{datetime.now(UTC).strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
        "OUT_DOCX = f\"/mnt/data/mronj_prevention_human_review_log_{datetime.now(UTC).strftime('%Y%m%d_%H%M%S')}.docx\"\n",
        "\n",
        "DRIVER_MODEL = \"gpt-5.2\"\n",
        "VERIFIER_MODEL = \"gemini-3-pro-preview\"\n",
        "\n",
        "REASONING_EFFORT_OPENAI = \"medium\"   # none|low|medium|high|xhigh\n",
        "THINKING_LEVEL_GEMINI = \"low\"        # minimal|low|high\n",
        "\n",
        "MAX_VIEW_CHARS = 60000\n",
        "VERIFIER_CHUNK_SIZE = 24\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# EXCEL MAP (template-specific)\n",
        "# -------------------------\n",
        "EXCEL_MAP = {\n",
        "    \"sheet_key_to_name\": {\n",
        "        \"included_articles\": \"Included Articles\",\n",
        "        \"level_of_evidence\": \"Level of Evidence\",\n",
        "        \"rct_appraisal\": \"Critical Appraisal of RCTS\",\n",
        "        \"cohort_appraisal\": \"Critical Appraisal of Cohort\",\n",
        "        \"case_series_appraisal\": \"Critical Appraisal of Case Seri\",\n",
        "        \"case_control_appraisal\": \"Critical Appraisal of Case Cont\",\n",
        "        \"systematic_appraisal\": \"Critical Appraisal of Systemati\",\n",
        "    },\n",
        "    \"sheets\": {\n",
        "        \"included_articles\": {\n",
        "            \"header_rows\": 3,\n",
        "            \"key\": {\"field\": \"pmid\", \"col\": \"A\"},\n",
        "            \"columns\": {\n",
        "                \"pmid\": \"A\",\n",
        "                \"author\": \"B\",\n",
        "                \"year\": \"C\",\n",
        "                \"study_design\": \"D\",\n",
        "                \"n_pts\": \"E\",\n",
        "                \"age_mean_years\": \"F\",\n",
        "                \"gender_male_n\": \"G\",\n",
        "                \"gender_female_n\": \"H\",\n",
        "                \"site_maxilla\": \"I\",\n",
        "                \"site_mandible\": \"J\",\n",
        "                \"site_both\": \"K\",\n",
        "                \"primary_cause_breast_cancer\": \"L\",\n",
        "                \"primary_cause_prostate_cancer\": \"M\",\n",
        "                \"primary_cause_mm\": \"N\",\n",
        "                \"primary_cause_osteoporosis\": \"O\",\n",
        "                \"primary_cause_other\": \"P\",\n",
        "                \"primary_cause_other_details\": \"Q\",\n",
        "                \"ards_bisphosphonates_alendronate\": \"R\",\n",
        "                \"ards_bisphosphonates_zoledronate\": \"S\",\n",
        "                \"ards_bisphosphonates_risedronate\": \"T\",\n",
        "                \"ards_bisphosphonates_neridronate\": \"U\",\n",
        "                \"ards_bisphosphonates_pamidronate\": \"V\",\n",
        "                \"ards_bisphosphonates_others\": \"W\",\n",
        "                \"ards_bisphosphonates_others_details\": \"X\",\n",
        "                \"ards_denosumab\": \"Z\",\n",
        "                \"ards_both\": \"AA\",\n",
        "                \"ards_other_drug\": \"Y\",\n",
        "                \"ards_other_drug_details\": \"AD\",\n",
        "                \"route_iv\": \"AB\",\n",
        "                \"route_oral\": \"AC\",\n",
        "                \"route_im\": \"AE\",\n",
        "                \"route_subcutaneous\": \"AF\",\n",
        "                \"route_both\": \"AG\",\n",
        "                \"route_not_reported\": \"AA\",  # kept as mapped in template (if present in your file; adjust if needed)\n",
        "                \"mronj_stage_at_risk\": \"AH\",\n",
        "                \"mronj_stage_0\": \"AI\",\n",
        "                \"prevention_technique\": \"AJ\",\n",
        "                \"group_intervention\": \"AK\",\n",
        "                \"group_control\": \"AL\",\n",
        "                \"follow_up_mean_months\": \"AM\",\n",
        "                \"follow_up_range\": \"AN\",\n",
        "                \"outcome_variable\": \"AO\",\n",
        "                \"mronj_development\": \"AP\",\n",
        "                \"mronj_development_details\": \"AQ\",\n",
        "            },\n",
        "        },\n",
        "        \"level_of_evidence\": {\n",
        "            \"header_rows\": 1,\n",
        "            \"key\": {\"field\": \"pmid\", \"col\": \"A\"},\n",
        "            \"columns\": {\n",
        "                \"pmid\": \"A\",\n",
        "                \"author\": \"B\",\n",
        "                \"year\": \"C\",\n",
        "                \"study_design\": \"D\",\n",
        "                \"level_of_evidence\": \"E\",\n",
        "                \"grade_of_recommendation\": \"F\",\n",
        "            },\n",
        "        },\n",
        "        \"rct_appraisal\": {\n",
        "            \"header_rows\": 3,\n",
        "            \"key\": {\"field\": \"pmid\", \"col\": \"A\"},\n",
        "            \"columns\": {\n",
        "                \"pmid\": \"A\",\n",
        "                \"author\": \"B\",\n",
        "                \"year\": \"C\",\n",
        "                \"study_design\": \"D\",\n",
        "                \"q1_randomized\": \"E\",\n",
        "                \"q2_randomization_method\": \"F\",\n",
        "                \"q3_double_blind\": \"G\",\n",
        "                \"q4_blinding_method\": \"H\",\n",
        "                \"q5_withdrawals\": \"I\",\n",
        "                \"total_score\": \"J\",\n",
        "            },\n",
        "        },\n",
        "        \"cohort_appraisal\": {\n",
        "            \"header_rows\": 2,\n",
        "            \"key\": {\"field\": \"pmid\", \"col\": \"A\"},\n",
        "            \"columns\": {\n",
        "                \"pmid\": \"A\",\n",
        "                \"author\": \"B\",\n",
        "                \"year\": \"C\",\n",
        "                \"study_design\": \"D\",\n",
        "                \"q1_clear_question\": \"E\",\n",
        "                \"q2_cohort_recruited\": \"F\",\n",
        "                \"q3_exposure_measured\": \"G\",\n",
        "                \"q4_outcome_measured\": \"H\",\n",
        "                \"q5_confounders\": \"I\",\n",
        "                \"q6_followup_complete\": \"J\",\n",
        "                \"total_score\": \"K\",\n",
        "            },\n",
        "        },\n",
        "        \"case_series_appraisal\": {\n",
        "            \"header_rows\": 2,\n",
        "            \"key\": {\"field\": \"pmid\", \"col\": \"A\"},\n",
        "            \"columns\": {\n",
        "                \"pmid\": \"A\",\n",
        "                \"author\": \"B\",\n",
        "                \"year\": \"C\",\n",
        "                \"study_design\": \"D\",\n",
        "                \"q1_clear_aim\": \"E\",\n",
        "                \"q2_inclusion_criteria\": \"F\",\n",
        "                \"q3_consecutive_cases\": \"G\",\n",
        "                \"q4_outcomes_defined\": \"H\",\n",
        "                \"q5_followup_sufficient\": \"I\",\n",
        "                \"q6_statistical_analysis\": \"J\",\n",
        "                \"total_score\": \"K\",\n",
        "            },\n",
        "        },\n",
        "        \"case_control_appraisal\": {\n",
        "            \"header_rows\": 2,\n",
        "            \"key\": {\"field\": \"pmid\", \"col\": \"A\"},\n",
        "            \"columns\": {\n",
        "                \"pmid\": \"A\",\n",
        "                \"author\": \"B\",\n",
        "                \"year\": \"C\",\n",
        "                \"study_design\": \"D\",\n",
        "                \"q1_clear_question\": \"E\",\n",
        "                \"q2_cases_representative\": \"F\",\n",
        "                \"q3_controls_selected\": \"G\",\n",
        "                \"q4_exposure_measured\": \"H\",\n",
        "                \"q5_confounders\": \"I\",\n",
        "                \"q6_results_precise\": \"J\",\n",
        "                \"total_score\": \"K\",\n",
        "            },\n",
        "        },\n",
        "        \"systematic_appraisal\": {\n",
        "            \"header_rows\": 3,\n",
        "            \"key\": {\"field\": \"pmid\", \"col\": \"A\"},\n",
        "            \"columns\": {\n",
        "                \"pmid\": \"A\",\n",
        "                \"author\": \"B\",\n",
        "                \"year\": \"C\",\n",
        "                \"study_design\": \"D\",\n",
        "                \"q1_focus_question\": \"E\",\n",
        "                \"q2_inclusion_criteria\": \"F\",\n",
        "                \"q3_comprehensive_search\": \"G\",\n",
        "                \"q4_6_search_and_duplication\": \"H\",\n",
        "                \"q7_quality_assessed\": \"I\",\n",
        "                \"q8_combining_appropriate\": \"J\",\n",
        "                \"q9_conclusions_supported\": \"K\",\n",
        "                \"total_score\": \"L\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# JSON SCHEMAS (strict top-level)\n",
        "# -------------------------\n",
        "def build_sheet_schema(columns):\n",
        "    field_types = [\"string\", \"number\", \"integer\", \"boolean\", \"null\"]\n",
        "    return {\n",
        "        \"type\": \"object\",\n",
        "        \"additionalProperties\": False,\n",
        "        \"required\": list(columns),\n",
        "        \"properties\": {key: {\"type\": field_types} for key in columns},\n",
        "    }\n",
        "\n",
        "SHEET_SCHEMAS = {\n",
        "    sheet_key: build_sheet_schema((cfg.get(\"columns\") or {}).keys())\n",
        "    for sheet_key, cfg in (EXCEL_MAP.get(\"sheets\") or {}).items()\n",
        "}\n",
        "SCALAR_TYPES = [\"string\", \"number\", \"integer\", \"boolean\", \"null\"]\n",
        "DRIVER_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"additionalProperties\": False,\n",
        "    \"required\": [\"paper_id\", \"study_type\", \"record\", \"critical_decisions\", \"confidence\", \"notes\"],\n",
        "    \"properties\": {\n",
        "        \"paper_id\": {\n",
        "            \"type\": \"object\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"required\": [\"pmid\", \"doi\", \"title\"],\n",
        "            \"properties\": {\n",
        "                \"pmid\": {\"type\": [\"integer\", \"null\"]},\n",
        "                \"doi\": {\"type\": [\"string\", \"null\"]},\n",
        "                \"title\": {\"type\": [\"string\", \"null\"]},\n",
        "            },\n",
        "        },\n",
        "        \"study_type\": {\n",
        "            \"type\": \"string\",\n",
        "            \"enum\": [\"rct\", \"cohort\", \"case_series\", \"case_control\", \"systematic_review\", \"other\", \"unclear\"],\n",
        "        },\n",
        "        \"record\": {\n",
        "            \"type\": \"object\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"required\": [\"sheets\"],\n",
        "            \"properties\": {\n",
        "                \"sheets\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"required\": [\n",
        "                        \"included_articles\",\n",
        "                        \"level_of_evidence\",\n",
        "                        \"rct_appraisal\",\n",
        "                        \"cohort_appraisal\",\n",
        "                        \"case_series_appraisal\",\n",
        "                        \"case_control_appraisal\",\n",
        "                        \"systematic_appraisal\",\n",
        "                    ],\n",
        "                    \"properties\": {\n",
        "                        \"included_articles\": {\"anyOf\": [SHEET_SCHEMAS[\"included_articles\"], {\"type\": \"null\"}]},\n",
        "                        \"level_of_evidence\": {\"anyOf\": [SHEET_SCHEMAS[\"level_of_evidence\"], {\"type\": \"null\"}]},\n",
        "                        \"rct_appraisal\": {\"anyOf\": [SHEET_SCHEMAS[\"rct_appraisal\"], {\"type\": \"null\"}]},\n",
        "                        \"cohort_appraisal\": {\"anyOf\": [SHEET_SCHEMAS[\"cohort_appraisal\"], {\"type\": \"null\"}]},\n",
        "                        \"case_series_appraisal\": {\"anyOf\": [SHEET_SCHEMAS[\"case_series_appraisal\"], {\"type\": \"null\"}]},\n",
        "                        \"case_control_appraisal\": {\"anyOf\": [SHEET_SCHEMAS[\"case_control_appraisal\"], {\"type\": \"null\"}]},\n",
        "                        \"systematic_appraisal\": {\"anyOf\": [SHEET_SCHEMAS[\"systematic_appraisal\"], {\"type\": \"null\"}]},\n",
        "                    },\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "        \"critical_decisions\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "                \"type\": \"object\",\n",
        "                \"additionalProperties\": False,\n",
        "                \"required\": [\"path\", \"value\", \"evidence\", \"is_critical\"],\n",
        "                \"properties\": {\n",
        "                    \"path\": {\"type\": \"string\"},\n",
        "                    \"value\": {\"type\": SCALAR_TYPES},\n",
        "                    \"evidence\": {\"type\": \"string\"},\n",
        "                    \"is_critical\": {\"type\": \"boolean\"},\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "        \"confidence\": {\"type\": \"number\", \"minimum\": 0.0, \"maximum\": 1.0},\n",
        "        \"notes\": {\"type\": \"string\"},\n",
        "    },\n",
        "}\n",
        "\n",
        "VERIFIER_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"additionalProperties\": False,\n",
        "    \"required\": [\"verdict\", \"critical_errors\", \"decision_reviews\", \"suggested_patch\", \"rationale\", \"confidence\"],\n",
        "    \"properties\": {\n",
        "        \"verdict\": {\"type\": \"string\", \"enum\": [\"AGREE\", \"DISAGREE\", \"UNSURE\"]},\n",
        "        \"critical_errors\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "        \"decision_reviews\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "                \"type\": \"object\",\n",
        "                \"additionalProperties\": False,\n",
        "                \"required\": [\"path\", \"is_critical\", \"status\", \"driver_value\", \"proposed_value\", \"explanation\", \"evidence\"],\n",
        "                \"properties\": {\n",
        "                    \"path\": {\"type\": \"string\"},\n",
        "                    \"is_critical\": {\"type\": \"boolean\"},\n",
        "                    \"status\": {\"type\": \"string\", \"enum\": [\"AGREE\", \"DISAGREE\", \"UNSURE\"]},\n",
        "                    \"driver_value\": {\"type\": SCALAR_TYPES},\n",
        "                    \"proposed_value\": {\"type\": SCALAR_TYPES},\n",
        "                    \"explanation\": {\"type\": \"string\"},\n",
        "                    \"evidence\": {\"type\": \"string\"},\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "        \"suggested_patch\": {\"type\": [\"object\", \"null\"]},\n",
        "        \"rationale\": {\"type\": \"string\"},\n",
        "        \"confidence\": {\"type\": \"number\", \"minimum\": 0.0, \"maximum\": 1.0},\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# PIPELINE CORE (validator + excel + word)\n",
        "# -------------------------\n",
        "def json_pointer_get(obj, pointer):\n",
        "    if pointer == \"\" or pointer == \"/\":\n",
        "        return obj\n",
        "    parts = pointer.lstrip(\"/\").split(\"/\")\n",
        "    cur = obj\n",
        "    for p in parts:\n",
        "        p = p.replace(\"~1\", \"/\").replace(\"~0\", \"~\")\n",
        "        if isinstance(cur, list):\n",
        "            cur = cur[int(p)]\n",
        "        else:\n",
        "            cur = cur.get(p)\n",
        "    return cur\n",
        "\n",
        "def json_pointer_set(obj, pointer, value):\n",
        "    parts = pointer.lstrip(\"/\").split(\"/\")\n",
        "    cur = obj\n",
        "    for i, p in enumerate(parts):\n",
        "        p = p.replace(\"~1\", \"/\").replace(\"~0\", \"~\")\n",
        "        last = (i == len(parts) - 1)\n",
        "        if last:\n",
        "            if isinstance(cur, list):\n",
        "                cur[int(p)] = value\n",
        "            else:\n",
        "                cur[p] = value\n",
        "        else:\n",
        "            if isinstance(cur, list):\n",
        "                cur = cur[int(p)]\n",
        "            else:\n",
        "                if p not in cur or not isinstance(cur[p], (dict, list)):\n",
        "                    cur[p] = {}\n",
        "                cur = cur[p]\n",
        "\n",
        "def deep_merge(a, b):\n",
        "    if not isinstance(a, dict) or not isinstance(b, dict):\n",
        "        return copy.deepcopy(b)\n",
        "    out = copy.deepcopy(a)\n",
        "    for k, v in b.items():\n",
        "        if k in out and isinstance(out[k], dict) and isinstance(v, dict):\n",
        "            out[k] = deep_merge(out[k], v)\n",
        "        else:\n",
        "            out[k] = copy.deepcopy(v)\n",
        "    return out\n",
        "\n",
        "def _normalize_excel_value(v):\n",
        "    if isinstance(v, bool):\n",
        "        return 1 if v else 0\n",
        "    if isinstance(v, str):\n",
        "        s = v.strip()\n",
        "        sl = s.lower()\n",
        "        if sl in (\"true\", \"yes\", \"y\", \"1\"):\n",
        "            return 1\n",
        "        if sl in (\"false\", \"no\", \"n\", \"0\"):\n",
        "            return 0\n",
        "        return s\n",
        "    return v\n",
        "\n",
        "def column_index_from_string(col):\n",
        "    col = col.upper().strip()\n",
        "    idx = 0\n",
        "    for c in col:\n",
        "        idx = idx * 26 + (ord(c) - ord(\"A\") + 1)\n",
        "    return idx\n",
        "\n",
        "def _find_or_create_row(ws, key_col_letter, key_value, header_rows):\n",
        "    key_col_idx = column_index_from_string(key_col_letter)\n",
        "    start_row = header_rows + 1\n",
        "    max_row = max(ws.max_row, start_row)\n",
        "\n",
        "    if key_value not in (None, \"\"):\n",
        "        for r in range(start_row, max_row + 1):\n",
        "            if ws.cell(r, key_col_idx).value == key_value:\n",
        "                return r\n",
        "\n",
        "    for r in range(start_row, max_row + 1):\n",
        "        if ws.cell(r, key_col_idx).value in (None, \"\"):\n",
        "            return r\n",
        "\n",
        "    return max_row + 1\n",
        "\n",
        "def apply_to_workbook(final_obj, template_xlsx, out_xlsx, excel_map):\n",
        "    wb = openpyxl.load_workbook(template_xlsx)\n",
        "    sheets_data = ((final_obj.get(\"record\") or {}).get(\"sheets\")) or {}\n",
        "    pmid = (final_obj.get(\"paper_id\") or {}).get(\"pmid\")\n",
        "\n",
        "    for sheet_key, payload in sheets_data.items():\n",
        "        if not isinstance(payload, dict):\n",
        "            continue\n",
        "        sheet_name = (excel_map.get(\"sheet_key_to_name\") or {}).get(sheet_key)\n",
        "        if not sheet_name or sheet_name not in wb.sheetnames:\n",
        "            continue\n",
        "\n",
        "        ws = wb[sheet_name]\n",
        "        sheet_cfg = (excel_map.get(\"sheets\") or {}).get(sheet_key) or {}\n",
        "        header_rows = int(sheet_cfg.get(\"header_rows\") or 1)\n",
        "        key_cfg = sheet_cfg.get(\"key\") or {\"field\": \"pmid\", \"col\": \"A\"}\n",
        "        key_col = key_cfg.get(\"col\") or \"A\"\n",
        "        row_idx = _find_or_create_row(ws, key_col, pmid, header_rows)\n",
        "\n",
        "        cols = sheet_cfg.get(\"columns\") or {}\n",
        "        for field, col_letter in cols.items():\n",
        "            if field == \"pmid\":\n",
        "                ws[f\"{col_letter}{row_idx}\"].value = pmid\n",
        "                continue\n",
        "            if field in payload:\n",
        "                ws[f\"{col_letter}{row_idx}\"].value = _normalize_excel_value(payload.get(field))\n",
        "\n",
        "        inc = sheets_data.get(\"included_articles\") or {}\n",
        "        if isinstance(inc, dict):\n",
        "            for f in (\"author\", \"year\", \"study_design\"):\n",
        "                if f in cols and ws[f\"{cols[f]}{row_idx}\"].value in (None, \"\"):\n",
        "                    if f in inc and inc.get(f) not in (None, \"\"):\n",
        "                        ws[f\"{cols[f]}{row_idx}\"].value = _normalize_excel_value(inc.get(f))\n",
        "\n",
        "    wb.save(out_xlsx)\n",
        "\n",
        "def compute_scores_inplace(driver_out):\n",
        "    sheets = (driver_out.get(\"record\") or {}).get(\"sheets\") or {}\n",
        "\n",
        "    rct = sheets.get(\"rct_appraisal\")\n",
        "    if isinstance(rct, dict):\n",
        "        score = 0\n",
        "        for k in (\"q1_randomized\", \"q2_randomization_method\", \"q3_double_blind\", \"q4_blinding_method\", \"q5_withdrawals\"):\n",
        "            v = rct.get(k)\n",
        "            if v in (1, True, \"1\", \"true\", \"True\", \"YES\", \"Yes\"):\n",
        "                score += 1\n",
        "        rct[\"total_score\"] = score\n",
        "\n",
        "    for key in (\"cohort_appraisal\", \"case_series_appraisal\", \"case_control_appraisal\", \"systematic_appraisal\"):\n",
        "        sd = sheets.get(key)\n",
        "        if isinstance(sd, dict):\n",
        "            score = 0\n",
        "            for k, v in sd.items():\n",
        "                if str(k).startswith(\"q\") and v in (1, True, \"1\", \"true\", \"True\", \"YES\", \"Yes\"):\n",
        "                    score += 1\n",
        "            sd[\"total_score\"] = score\n",
        "\n",
        "def infer_all_leaf_paths(driver_out):\n",
        "    paths = [\"/study_type\"]\n",
        "\n",
        "    def walk(base, obj):\n",
        "        if isinstance(obj, dict):\n",
        "            for k, v in obj.items():\n",
        "                p = base + \"/\" + str(k).replace(\"~\", \"~0\").replace(\"/\", \"~1\")\n",
        "                if isinstance(v, dict):\n",
        "                    walk(p, v)\n",
        "                elif isinstance(v, list):\n",
        "                    for i, it in enumerate(v):\n",
        "                        walk(p + f\"/{i}\", it)\n",
        "                else:\n",
        "                    paths.append(p)\n",
        "        elif isinstance(obj, list):\n",
        "            for i, it in enumerate(obj):\n",
        "                walk(base + f\"/{i}\", it)\n",
        "\n",
        "    record = driver_out.get(\"record\") or {}\n",
        "    sheets = (record.get(\"sheets\") or {})\n",
        "    for sheet_key, payload in sheets.items():\n",
        "        if isinstance(payload, dict):\n",
        "            walk(f\"/record/sheets/{sheet_key}\", payload)\n",
        "\n",
        "    out = []\n",
        "    seen = set()\n",
        "    for p in paths:\n",
        "        if p not in seen:\n",
        "            out.append(p)\n",
        "            seen.add(p)\n",
        "    return out\n",
        "\n",
        "def rule_validation(merged_driver):\n",
        "    issues = []\n",
        "    sheets = (merged_driver.get(\"record\") or {}).get(\"sheets\") or {}\n",
        "    inc = sheets.get(\"included_articles\") or {}\n",
        "\n",
        "    def _count_true(keys):\n",
        "        c = 0\n",
        "        for k in keys:\n",
        "            v = inc.get(k)\n",
        "            if v in (True, 1, \"1\", \"true\", \"True\", \"YES\", \"Yes\"):\n",
        "                c += 1\n",
        "        return c\n",
        "\n",
        "    site_keys = [\"site_maxilla\", \"site_mandible\", \"site_both\"]\n",
        "    if _count_true(site_keys) == 0:\n",
        "        issues.append({\"severity\": \"WARN\", \"code\": \"SITE_EMPTY\", \"message\": \"No site marked (maxilla/mandible/both).\", \"path\": \"/record/sheets/included_articles\"})\n",
        "    if _count_true(site_keys) > 1 and not (inc.get(\"site_both\") in (True, 1, \"1\", \"true\", \"True\")):\n",
        "        issues.append({\"severity\": \"WARN\", \"code\": \"SITE_INCONSISTENT\", \"message\": \"Multiple site flags set but site_both not set.\", \"path\": \"/record/sheets/included_articles\"})\n",
        "\n",
        "    route_keys = [\"route_iv\", \"route_oral\", \"route_im\", \"route_subcutaneous\", \"route_both\", \"route_not_reported\"]\n",
        "    if _count_true(route_keys) == 0:\n",
        "        issues.append({\"severity\": \"WARN\", \"code\": \"ROUTE_EMPTY\", \"message\": \"No route marked.\", \"path\": \"/record/sheets/included_articles\"})\n",
        "    if inc.get(\"route_both\") in (True, 1, \"1\", \"true\", \"True\") and _count_true([\"route_iv\", \"route_oral\", \"route_im\", \"route_subcutaneous\"]) == 0:\n",
        "        issues.append({\"severity\": \"WARN\", \"code\": \"ROUTE_BOTH_NO_DETAILS\", \"message\": \"route_both is set but no specific route marked.\", \"path\": \"/record/sheets/included_articles\"})\n",
        "    if inc.get(\"route_not_reported\") in (True, 1, \"1\", \"true\", \"True\") and _count_true([\"route_iv\", \"route_oral\", \"route_im\", \"route_subcutaneous\", \"route_both\"]) > 0:\n",
        "        issues.append({\"severity\": \"WARN\", \"code\": \"ROUTE_NR_CONFLICT\", \"message\": \"route_not_reported is set but other route flags are also set.\", \"path\": \"/record/sheets/included_articles\"})\n",
        "\n",
        "    mdev = inc.get(\"mronj_development\")\n",
        "    if isinstance(mdev, str) and mdev.strip().lower() not in (\"yes\", \"no\", \"unclear\", \"n/a\", \"na\", \"nr\", \"not reported\"):\n",
        "        issues.append({\"severity\": \"WARN\", \"code\": \"MRONJ_DEV_UNEXPECTED\", \"message\": \"mronj_development is not a standard token (Yes/No/Unclear).\", \"path\": \"/record/sheets/included_articles/mronj_development\"})\n",
        "\n",
        "    return issues\n",
        "\n",
        "def compile_critical_decision_report(passes, critical_paths, final_driver):\n",
        "    issues = []\n",
        "    latest_review_by_path = {}\n",
        "    for p in passes:\n",
        "        for dr in (p.get(\"decision_reviews\") or []):\n",
        "            path = dr.get(\"path\")\n",
        "            if path:\n",
        "                latest_review_by_path[path] = dr\n",
        "\n",
        "    critical_report = []\n",
        "    for path in critical_paths:\n",
        "        review = latest_review_by_path.get(path)\n",
        "        if review is None:\n",
        "            critical_report.append({\n",
        "                \"path\": path,\n",
        "                \"final_value\": json_pointer_get(final_driver, path),\n",
        "                \"status\": \"MISSING\",\n",
        "                \"explanation\": \"Missing verifier review for critical decision.\",\n",
        "                \"evidence\": \"\",\n",
        "            })\n",
        "            issues.append({\n",
        "                \"severity\": \"CRITICAL\",\n",
        "                \"code\": \"MISSING_VERIFIER_REVIEW\",\n",
        "                \"message\": f\"Critical decision not reviewed by verifier: {path}\",\n",
        "                \"path\": path,\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        status = review.get(\"status\", \"UNSURE\")\n",
        "        final_val = review.get(\"proposed_value\", review.get(\"driver_value\"))\n",
        "\n",
        "        critical_report.append({\n",
        "            \"path\": path,\n",
        "            \"final_value\": final_val,\n",
        "            \"status\": status,\n",
        "            \"explanation\": review.get(\"explanation\", \"\"),\n",
        "            \"evidence\": review.get(\"evidence\", \"\"),\n",
        "        })\n",
        "\n",
        "        if status in (\"DISAGREE\", \"UNSURE\"):\n",
        "            issues.append({\n",
        "                \"severity\": \"CRITICAL\",\n",
        "                \"code\": f\"VERIFIER_{status}\",\n",
        "                \"message\": f\"Verifier status {status} for critical decision: {path}\",\n",
        "                \"path\": path,\n",
        "            })\n",
        "\n",
        "    return critical_report, issues\n",
        "\n",
        "def write_human_review_docx(final_obj, docx_path, append=True):\n",
        "    if append and os.path.exists(docx_path):\n",
        "        doc = Document(docx_path)\n",
        "        doc.add_page_break()\n",
        "    else:\n",
        "        doc = Document()\n",
        "        doc.add_heading(\"MRONJ prevention extraction - human review log\", level=0)\n",
        "\n",
        "    paper_id = final_obj.get(\"paper_id\") or {}\n",
        "    pmid = paper_id.get(\"pmid\")\n",
        "    doi = paper_id.get(\"doi\")\n",
        "    title = paper_id.get(\"title\")\n",
        "\n",
        "    doc.add_heading(f\"PMID: {pmid if pmid is not None else 'null'}\", level=1)\n",
        "    if title:\n",
        "        doc.add_paragraph(\"Title: \" + str(title))\n",
        "    if doi:\n",
        "        doc.add_paragraph(\"DOI: \" + str(doi))\n",
        "\n",
        "    doc.add_paragraph(\"Study type: \" + str(final_obj.get(\"study_type\")))\n",
        "\n",
        "    needs = ((final_obj.get(\"validation\") or {}).get(\"needs_human_review\"))\n",
        "    doc.add_paragraph(\"Needs human review: \" + (\"YES\" if needs else \"NO\"))\n",
        "\n",
        "    doc.add_heading(\"Critical decisions (verifier)\", level=2)\n",
        "    t = doc.add_table(rows=1, cols=4)\n",
        "    t.style = \"Table Grid\"\n",
        "    hdr = t.rows[0].cells\n",
        "    hdr[0].text = \"path\"\n",
        "    hdr[1].text = \"status\"\n",
        "    hdr[2].text = \"explanation\"\n",
        "    hdr[3].text = \"evidence\"\n",
        "\n",
        "    for cd in (final_obj.get(\"verification\") or {}).get(\"critical_decisions\") or []:\n",
        "        r = t.add_row().cells\n",
        "        r[0].text = str(cd.get(\"path\", \"\"))\n",
        "        r[1].text = str(cd.get(\"status\", \"\"))\n",
        "        r[2].text = str(cd.get(\"explanation\", \"\"))\n",
        "        r[3].text = str(cd.get(\"evidence\", \"\"))\n",
        "\n",
        "    doc.add_heading(\"Validation issues\", level=2)\n",
        "    issues = (final_obj.get(\"validation\") or {}).get(\"issues\") or []\n",
        "    if not issues:\n",
        "        doc.add_paragraph(\"None.\")\n",
        "    else:\n",
        "        for it in issues:\n",
        "            doc.add_paragraph(f\"[{it.get('severity')}] {it.get('code')}: {it.get('message')} (path={it.get('path')})\")\n",
        "\n",
        "    doc.add_heading(\"Verifier passes summary\", level=2)\n",
        "    passes = (final_obj.get(\"verification\") or {}).get(\"passes\") or []\n",
        "    for i, p in enumerate(passes, 1):\n",
        "        doc.add_paragraph(f\"pass {i}: verdict={p.get('verdict')} confidence={p.get('confidence')} errors={'; '.join(p.get('critical_errors') or [])}\")\n",
        "\n",
        "    doc.save(docx_path)\n",
        "\n",
        "def build_final_object(driver_out, verifier_passes, verifier_model=None, version=\"2.1\"):\n",
        "    merged = copy.deepcopy(driver_out)\n",
        "    for p in verifier_passes:\n",
        "        patch = p.get(\"suggested_patch\")\n",
        "        if isinstance(patch, dict) and patch:\n",
        "            merged = deep_merge(merged, patch)\n",
        "\n",
        "    compute_scores_inplace(merged)\n",
        "\n",
        "    critical_paths = infer_all_leaf_paths(merged)\n",
        "\n",
        "    critical_report, issues = compile_critical_decision_report(verifier_passes, critical_paths, merged)\n",
        "    issues.extend(rule_validation(merged))\n",
        "\n",
        "    final_obj = {\n",
        "        \"version\": version,\n",
        "        \"paper_id\": merged.get(\"paper_id\") or {\"pmid\": None, \"doi\": None, \"title\": None},\n",
        "        \"study_type\": merged.get(\"study_type\", \"unclear\"),\n",
        "        \"record\": merged.get(\"record\") or {\"sheets\": {}},\n",
        "        \"verification\": {\n",
        "            \"verifier_model\": verifier_model,\n",
        "            \"passes\": verifier_passes,\n",
        "            \"critical_decisions\": critical_report,\n",
        "        },\n",
        "        \"validation\": {\n",
        "            \"needs_human_review\": any(i.get(\"severity\") == \"CRITICAL\" for i in issues),\n",
        "            \"issues\": issues,\n",
        "        },\n",
        "    }\n",
        "    return final_obj\n",
        "\n",
        "def apply_final_to_outputs(final_obj, template_xlsx, out_xlsx, excel_map, review_docx_path):\n",
        "    passes = ((final_obj.get(\"verification\") or {}).get(\"passes\")) or []\n",
        "    if not passes:\n",
        "        raise RuntimeError(\"No verifier passes provided. Refusing to write outputs.\")\n",
        "    apply_to_workbook(final_obj, template_xlsx, out_xlsx, excel_map)\n",
        "    write_human_review_docx(final_obj, review_docx_path, append=True)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# PDF TEXT + VIEW\n",
        "# -------------------------\n",
        "def extract_pdf_text(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    parts = []\n",
        "    for i in range(doc.page_count):\n",
        "        parts.append(doc.load_page(i).get_text(\"text\"))\n",
        "    doc.close()\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "def make_view(full_text, max_chars=MAX_VIEW_CHARS):\n",
        "    t = re.sub(r\"[ \\t]+\\n\", \"\\n\", full_text)\n",
        "    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
        "    tl = t.lower()\n",
        "\n",
        "    def win_at(needle, span=12000):\n",
        "        idx = tl.find(needle)\n",
        "        if idx == -1:\n",
        "            return \"\"\n",
        "        start = max(0, idx - 1500)\n",
        "        end = min(len(t), idx + span)\n",
        "        return t[start:end]\n",
        "\n",
        "    chunks = []\n",
        "    chunks.append(t[:7000])\n",
        "    for key in [\n",
        "        \"abstract\",\n",
        "        \"introduction\",\n",
        "        \"methods\",\n",
        "        \"materials and methods\",\n",
        "        \"results\",\n",
        "        \"discussion\",\n",
        "        \"conclusion\",\n",
        "        \"table\",\n",
        "        \"supplement\",\n",
        "    ]:\n",
        "        c = win_at(key)\n",
        "        if c:\n",
        "            chunks.append(\"\\n\\n===== \" + key.upper() + \" (WINDOW) =====\\n\" + c)\n",
        "\n",
        "    combined = \"\\n\".join(chunks)\n",
        "    return combined[:max_chars]\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# PROMPTS\n",
        "# -------------------------\n",
        "INCLUDED_KEYS = [\n",
        "    \"pmid\",\"author\",\"year\",\"study_design\",\n",
        "    \"n_pts\",\"age_mean_years\",\"gender_male_n\",\"gender_female_n\",\n",
        "    \"site_maxilla\",\"site_mandible\",\"site_both\",\n",
        "    \"primary_cause_breast_cancer\",\"primary_cause_prostate_cancer\",\"primary_cause_mm\",\"primary_cause_osteoporosis\",\"primary_cause_other\",\"primary_cause_other_details\",\n",
        "    \"ards_bisphosphonates_alendronate\",\"ards_bisphosphonates_zoledronate\",\"ards_bisphosphonates_risedronate\",\"ards_bisphosphonates_neridronate\",\"ards_bisphosphonates_pamidronate\",\n",
        "    \"ards_bisphosphonates_others\",\"ards_bisphosphonates_others_details\",\n",
        "    \"ards_denosumab\",\"ards_both\",\"ards_other_drug\",\"ards_other_drug_details\",\n",
        "    \"route_iv\",\"route_oral\",\"route_im\",\"route_subcutaneous\",\"route_both\",\"route_not_reported\",\n",
        "    \"mronj_stage_at_risk\",\"mronj_stage_0\",\n",
        "    \"prevention_technique\",\"group_intervention\",\"group_control\",\n",
        "    \"follow_up_mean_months\",\"follow_up_range\",\"outcome_variable\",\n",
        "    \"mronj_development\",\"mronj_development_details\",\n",
        "]\n",
        "\n",
        "DRIVER_SYSTEM = (\n",
        "    \"You are an evidence extraction agent for MRONJ prevention literature.\\n\"\n",
        "    \"Use ONLY the provided paper text. Do not guess.\\n\"\n",
        "    \"If uncertain, use null and lower confidence.\\n\"\n",
        "    \"Evidence must be short (1 sentence), no long quotes.\\n\"\n",
        "    \"You MUST return strict JSON that matches the provided schema.\\n\"\n",
        ")\n",
        "\n",
        "DRIVER_USER_TEMPLATE = (\n",
        "    \"TASK:\\n\"\n",
        "    \"A) Identify paper_id (pmid/doi/title) if present.\\n\"\n",
        "    \"B) Classify study_type as one of: rct|cohort|case_series|case_control|systematic_review|other|unclear.\\n\"\n",
        "    \"C) Fill record.sheets.included_articles with the keys listed below (use null if not reported).\\n\"\n",
        "    \"D) Fill record.sheets.level_of_evidence if the paper explicitly states it; else null.\\n\"\n",
        "    \"E) Fill exactly ONE appraisal sheet based on study_type, others must be null:\\n\"\n",
        "    \"   - rct -> rct_appraisal\\n\"\n",
        "    \"   - cohort -> cohort_appraisal\\n\"\n",
        "    \"   - case_series -> case_series_appraisal\\n\"\n",
        "    \"   - case_control -> case_control_appraisal\\n\"\n",
        "    \"   - systematic_review -> systematic_appraisal\\n\"\n",
        "    \"   - other/unclear -> all appraisal sheets null\\n\"\n",
        "    \"F) Appraisal questions: set 1 for Yes, 0 for No, null for unclear/not stated.\\n\"\n",
        "    \"G) critical_decisions: MUST contain an entry for study_type AND for EVERY non-null key you set anywhere in record.sheets.*.\\n\"\n",
        "    \"   Each entry MUST include:\\n\"\n",
        "    \"     - path (JSON pointer)\\n\"\n",
        "    \"     - value (the exact value you set)\\n\"\n",
        "    \"     - evidence (1 sentence)\\n\"\n",
        "    \"     - is_critical=true\\n\"\n",
        "    \"\\n\"\n",
        "    \"Normalization rules (important):\\n\"\n",
        "    \"- mronj_development must be one of: Yes|No|Unclear|NR\\n\"\n",
        "    \"- Site flags: set maxilla/mandible/both as applicable (null if NR).\\n\"\n",
        "    \"- Route flags: set the most specific route(s); if truly not reported set route_not_reported=1.\\n\"\n",
        "    \"- Drug flags: set specific bisphosphonate subtype(s) if stated; denosumab if stated; ards_both if both.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Included Articles keys to fill:\\n\"\n",
        "    f\"{', '.join(INCLUDED_KEYS)}\\n\"\n",
        "    \"\\n\"\n",
        "    \"PAPER_TEXT (VIEW):\\n\"\n",
        "    \"{VIEW}\\n\"\n",
        ")\n",
        "\n",
        "VERIFIER_SYSTEM = (\n",
        "    \"You are an independent verifier.\\n\"\n",
        "    \"Check whether each listed decision is supported by the provided paper text.\\n\"\n",
        "    \"For each decision: return AGREE, DISAGREE (with proposed_value), or UNSURE.\\n\"\n",
        "    \"Evidence must be short (1 sentence), no long quotes.\\n\"\n",
        "    \"If DISAGREE, propose the minimal corrected value.\\n\"\n",
        "    \"Also provide suggested_patch as a minimal JSON object patch (only the corrected fields).\\n\"\n",
        "    \"Return strict JSON that matches the provided schema.\\n\"\n",
        ")\n",
        "\n",
        "VERIFIER_USER_TEMPLATE = (\n",
        "    \"PAPER_TEXT (VIEW):\\n\"\n",
        "    \"{VIEW}\\n\\n\"\n",
        "    \"DRIVER_JSON (context):\\n\"\n",
        "    \"{DRIVER_JSON}\\n\\n\"\n",
        "    \"DECISIONS_TO_REVIEW (only review these):\\n\"\n",
        "    \"{DECISIONS_TO_REVIEW}\\n\"\n",
        ")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# LLM CALLS\n",
        "# -------------------------\n",
        "def openai_driver_extract(oai_client, view_text):\n",
        "    driver_user = DRIVER_USER_TEMPLATE.replace(\"{VIEW}\", view_text)\n",
        "    resp = oai_client.responses.create(\n",
        "        model=DRIVER_MODEL,\n",
        "        reasoning={\"effort\": REASONING_EFFORT_OPENAI},\n",
        "        input=[\n",
        "            {\"role\": \"system\", \"content\": DRIVER_SYSTEM},\n",
        "            {\"role\": \"user\", \"content\": driver_user},\n",
        "        ],\n",
        "        text={\"format\": {\"type\": \"json_schema\", \"name\": \"mronj_prevention_driver\", \"schema\": DRIVER_SCHEMA, \"strict\": True}},\n",
        "    )\n",
        "    return json.loads(resp.output_text)\n",
        "\n",
        "def gemini_verify_chunk(gclient, view_text, driver_json, decisions_to_review):\n",
        "    verifier_user = VERIFIER_USER_TEMPLATE.format(\n",
        "        VIEW=view_text,\n",
        "        DRIVER_JSON=json.dumps(driver_json, ensure_ascii=True),\n",
        "        DECISIONS_TO_REVIEW=json.dumps(decisions_to_review, ensure_ascii=True),\n",
        "    )\n",
        "    resp = gclient.models.generate_content(\n",
        "        model=VERIFIER_MODEL,\n",
        "        contents=verifier_user,\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=VERIFIER_SYSTEM,\n",
        "            response_mime_type=\"application/json\",\n",
        "            response_json_schema=VERIFIER_SCHEMA,\n",
        "            thinking_config=types.ThinkingConfig(thinking_level=THINKING_LEVEL_GEMINI),\n",
        "            temperature=0.0,\n",
        "        ),\n",
        "    )\n",
        "    return json.loads(resp.text)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# DECISION LIST + CHUNKING\n",
        "# -------------------------\n",
        "def build_decisions_from_driver(driver_out):\n",
        "    # Start with driver-provided decisions\n",
        "    out = []\n",
        "    seen = set()\n",
        "\n",
        "    for cd in (driver_out.get(\"critical_decisions\") or []):\n",
        "        path = cd.get(\"path\")\n",
        "        if not path or path in seen:\n",
        "            continue\n",
        "        out.append({\n",
        "            \"path\": path,\n",
        "            \"value\": cd.get(\"value\"),\n",
        "            \"evidence\": cd.get(\"evidence\", \"\"),\n",
        "            \"is_critical\": True,\n",
        "        })\n",
        "        seen.add(path)\n",
        "\n",
        "    # Ensure /study_type is present\n",
        "    if \"/study_type\" not in seen:\n",
        "        out.append({\n",
        "            \"path\": \"/study_type\",\n",
        "            \"value\": driver_out.get(\"study_type\"),\n",
        "            \"evidence\": \"Driver classification; verify against methods/abstract.\",\n",
        "            \"is_critical\": True,\n",
        "        })\n",
        "        seen.add(\"/study_type\")\n",
        "\n",
        "    # Ensure every leaf in record.sheets.* has a decision entry\n",
        "    leaf_paths = infer_all_leaf_paths(driver_out)\n",
        "    for p in leaf_paths:\n",
        "        if p in seen:\n",
        "            continue\n",
        "        v = json_pointer_get(driver_out, p)\n",
        "        # include null leaves too (still a decision), but keep evidence empty\n",
        "        out.append({\n",
        "            \"path\": p,\n",
        "            \"value\": v,\n",
        "            \"evidence\": \"\",\n",
        "            \"is_critical\": True,\n",
        "        })\n",
        "        seen.add(p)\n",
        "\n",
        "    return out\n",
        "\n",
        "def chunk_list(xs, n):\n",
        "    return [xs[i:i+n] for i in range(0, len(xs), n)]\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# RUNNER (Colab-ready)\n",
        "# -------------------------\n",
        "def _progress(progress_fn, message):\n",
        "    if progress_fn:\n",
        "        ts = datetime.now(UTC).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        progress_fn(f\"[{ts} UTC] {message}\")\n",
        "\n",
        "\n",
        "def run_pipeline_for_pdf(\n",
        "    pdf_path,\n",
        "    oai_client,\n",
        "    gclient,\n",
        "    template_xlsx,\n",
        "    out_xlsx,\n",
        "    out_docx,\n",
        "    progress_fn=print,\n",
        "):\n",
        "    _progress(progress_fn, f\"Starting PDF: {pdf_path}\")\n",
        "    _progress(progress_fn, \"Extracting text from PDF...\")\n",
        "    full_text = extract_pdf_text(pdf_path)\n",
        "    _progress(progress_fn, f\"PDF text extracted (chars={len(full_text)}). Building view...\")\n",
        "    view = make_view(full_text)\n",
        "    _progress(progress_fn, f\"View built (chars={len(view)}). Calling driver model...\")\n",
        "\n",
        "    driver_out = openai_driver_extract(oai_client, view)\n",
        "    _progress(progress_fn, \"Driver model completed. Building decision list...\")\n",
        "\n",
        "    # Build full decision list, then verify in chunks\n",
        "    decisions = build_decisions_from_driver(driver_out)\n",
        "    decision_chunks = chunk_list(decisions, VERIFIER_CHUNK_SIZE)\n",
        "    _progress(progress_fn, f\"Verifier round 1: {len(decision_chunks)} chunk(s).\")\n",
        "\n",
        "    verifier_passes = []\n",
        "    working_driver = copy.deepcopy(driver_out)\n",
        "\n",
        "    # Round 1: verify all decisions\n",
        "    for idx, ch in enumerate(decision_chunks, 1):\n",
        "        _progress(progress_fn, f\"Verifier round 1: chunk {idx}/{len(decision_chunks)}...\")\n",
        "        vpass = gemini_verify_chunk(gclient, view, working_driver, ch)\n",
        "        verifier_passes.append(vpass)\n",
        "\n",
        "        patch = vpass.get(\"suggested_patch\")\n",
        "        if isinstance(patch, dict) and patch:\n",
        "            working_driver = deep_merge(working_driver, patch)\n",
        "\n",
        "    # Round 2: re-verify only DISAGREE/UNSURE paths after patching\n",
        "    flagged_paths = []\n",
        "    for p in verifier_passes:\n",
        "        for dr in (p.get(\"decision_reviews\") or []):\n",
        "            if dr.get(\"status\") in (\"DISAGREE\", \"UNSURE\"):\n",
        "                flagged_paths.append(dr.get(\"path\"))\n",
        "\n",
        "    flagged_paths = [p for p in flagged_paths if p]\n",
        "    flagged_paths = list(dict.fromkeys(flagged_paths))  # de-dup preserving order\n",
        "    if flagged_paths:\n",
        "        _progress(progress_fn, f\"Verifier round 2: {len(flagged_paths)} flagged decision(s).\")\n",
        "        flagged_decisions = []\n",
        "        for p in flagged_paths:\n",
        "            flagged_decisions.append({\n",
        "                \"path\": p,\n",
        "                \"value\": json_pointer_get(working_driver, p),\n",
        "                \"evidence\": \"\",\n",
        "                \"is_critical\": True,\n",
        "            })\n",
        "        flagged_chunks = chunk_list(flagged_decisions, VERIFIER_CHUNK_SIZE)\n",
        "        for idx, ch in enumerate(flagged_chunks, 1):\n",
        "            _progress(progress_fn, f\"Verifier round 2: chunk {idx}/{len(flagged_chunks)}...\")\n",
        "            vpass2 = gemini_verify_chunk(gclient, view, working_driver, ch)\n",
        "            verifier_passes.append(vpass2)\n",
        "            patch2 = vpass2.get(\"suggested_patch\")\n",
        "            if isinstance(patch2, dict) and patch2:\n",
        "                working_driver = deep_merge(working_driver, patch2)\n",
        "    else:\n",
        "        _progress(progress_fn, \"Verifier round 2 skipped (no flagged decisions).\")\n",
        "\n",
        "    _progress(progress_fn, \"Building final object + writing outputs...\")\n",
        "    final_obj = build_final_object(working_driver, verifier_passes, verifier_model=VERIFIER_MODEL, version=\"2.1\")\n",
        "\n",
        "    # Persist: for first PDF, template_xlsx is the original template.\n",
        "    # For subsequent PDFs in the same run, call with template_xlsx=out_xlsx to accumulate rows.\n",
        "    apply_final_to_outputs(final_obj, template_xlsx, out_xlsx, EXCEL_MAP, out_docx)\n",
        "\n",
        "    # Also dump audit JSON alongside (optional)\n",
        "    audit_path = out_xlsx.replace(\".xlsx\", f\".audit_{(final_obj.get('paper_id') or {}).get('pmid')}.json\")\n",
        "    with open(audit_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(final_obj, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    _progress(progress_fn, f\"Completed PDF: {pdf_path}\")\n",
        "    return final_obj\n",
        "\n",
        "\n",
        "def run_pipeline(\n",
        "    pdf_paths=None,\n",
        "    template_xlsx=TEMPLATE_XLSX,\n",
        "    out_xlsx=OUT_XLSX,\n",
        "    out_docx=OUT_DOCX,\n",
        "    openai_api_key=None,\n",
        "    google_api_key=None,\n",
        "    progress_fn=print,\n",
        "):\n",
        "    if not pdf_paths:\n",
        "        raise RuntimeError(\"pdf_paths is empty. Provide at least one PDF path.\")\n",
        "    if not os.path.exists(template_xlsx):\n",
        "        raise FileNotFoundError(template_xlsx)\n",
        "\n",
        "    openai_key = openai_api_key or os.getenv(\"OPENAI_API_KEY\")\n",
        "    google_key = google_api_key or os.getenv(\"GOOGLE_API_KEY\")\n",
        "    if not openai_key:\n",
        "        raise RuntimeError(\"Missing OPENAI_API_KEY (env var or openai_api_key arg).\")\n",
        "    if not google_key:\n",
        "        raise RuntimeError(\"Missing GOOGLE_API_KEY (env var or google_api_key arg).\")\n",
        "\n",
        "    oai_client = OpenAI(api_key=openai_key)\n",
        "    gclient = genai.Client(api_key=google_key)\n",
        "\n",
        "    current_template = template_xlsx\n",
        "    finals = []\n",
        "\n",
        "    for pdf in pdf_paths:\n",
        "        if not os.path.exists(pdf):\n",
        "            raise FileNotFoundError(pdf)\n",
        "\n",
        "        final_obj = run_pipeline_for_pdf(\n",
        "            pdf_path=pdf,\n",
        "            oai_client=oai_client,\n",
        "            gclient=gclient,\n",
        "            template_xlsx=current_template,\n",
        "            out_xlsx=out_xlsx,\n",
        "            out_docx=out_docx,\n",
        "            progress_fn=progress_fn,\n",
        "        )\n",
        "        current_template = out_xlsx\n",
        "        finals.append(final_obj)\n",
        "\n",
        "        pid = final_obj.get(\"paper_id\") or {}\n",
        "        _progress(\n",
        "            progress_fn,\n",
        "            \"DONE pdf=\"\n",
        "            + str(pdf)\n",
        "            + \" pmid=\"\n",
        "            + str(pid.get(\"pmid\"))\n",
        "            + \" study_type=\"\n",
        "            + str(final_obj.get(\"study_type\"))\n",
        "            + \" needs_human_review=\"\n",
        "            + str((final_obj.get(\"validation\") or {}).get(\"needs_human_review\")),\n",
        "        )\n",
        "\n",
        "    _progress(progress_fn, f\"WROTE_XLSX: {out_xlsx}\")\n",
        "    _progress(progress_fn, f\"WROTE_DOCX: {out_docx}\")\n",
        "    return finals\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run\n",
        "\n",
        "Update the input paths and execute.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: configure inputs then run\n",
        "# PDF_PATHS = ['/content/paper1.pdf']\n",
        "# TEMPLATE_XLSX = '/content/Prevention of MRONJ_Extraction Sheet (Oli).xlsx'\n",
        "#\n",
        "# finals = run_pipeline(\n",
        "#     pdf_paths=PDF_PATHS,\n",
        "#     template_xlsx=TEMPLATE_XLSX,\n",
        "# )\n",
        "# finals\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}